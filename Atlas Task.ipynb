{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install torch tensorflow pandas numpy matplotlib tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T21:19:23.854674Z",
     "start_time": "2020-03-07T21:19:20.901420Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import tensorflow as tf #needed for tb logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T21:19:23.861273Z",
     "start_time": "2020-03-07T21:19:23.856274Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UTILITIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CONVERT NORMALISED VECTOR TO ORIGINAL FORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T21:19:23.865626Z",
     "start_time": "2020-03-07T21:19:23.863063Z"
    }
   },
   "outputs": [],
   "source": [
    "def unNormalise(inputs, mean, std):\n",
    "    \"\"\"\n",
    "    log to tensorboard using the writer object\n",
    "    \n",
    "    @params: inputs -> torch tensor of numpy.ndarray of normalised data (d1 x d2 x d3 ... x dn)\n",
    "    @params: mean -> mean of along the last dimension (d1 x d2 x d3 ..... x d(n-1) x 1)\n",
    "    @params: std -> std of along the last dimension (d1 x d2 x d3 ..... x d(n-1) x 1)\n",
    "    \n",
    "    @returns: unnormalised data (d1 x d2 x d3 .... x dn)\n",
    "    \"\"\"\n",
    "    return inputs*std + mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LOG TO TENSORBOARD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T21:19:23.872665Z",
     "start_time": "2020-03-07T21:19:23.867269Z"
    }
   },
   "outputs": [],
   "source": [
    "def log(writer, log_dict, epoch):\n",
    "    \"\"\"\n",
    "    log to tensorboard using the writer object\n",
    "    \n",
    "    @params: writer -> tf.writer object\n",
    "    @params: log_dict -> (name, value) pairs, log the value using the key (name) as the tag.\n",
    "    @params: epoch -> the iteration number for which logging is being done.\n",
    "    \"\"\"\n",
    "    \n",
    "    with writer.as_default():\n",
    "        for metric in log_dict:\n",
    "            tf.summary.scalar(metric, log_dict[metric], step=epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LOAD DATA GIVEN RELATIVE PATH FROM data_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T21:19:23.881988Z",
     "start_time": "2020-03-07T21:19:23.873778Z"
    }
   },
   "outputs": [],
   "source": [
    "def load(rel_path):\n",
    "    \"\"\"\n",
    "    load data from data_root/rel_path\n",
    "    \n",
    "    @params: rel_path -> path to a .pkl, relative to the data root global param.\n",
    "    \n",
    "    @returns: data -> loaded pandas df\n",
    "    \"\"\"\n",
    "    \n",
    "    path = os.path.join(data_root, rel_path)\n",
    "    with open(path, \"rb\") as f:\n",
    "        data = pd.read_pickle(f, compression=None)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MAKE DIRECTORY GIVEN THE PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T21:19:24.463397Z",
     "start_time": "2020-03-07T21:19:24.456802Z"
    }
   },
   "outputs": [],
   "source": [
    "def mkdir(*args, **kwargs):\n",
    "    try:\n",
    "        os.mkdir(*args, **kwargs)\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INITIALISATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T21:19:25.559765Z",
     "start_time": "2020-03-07T21:19:25.550901Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using:  cuda\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 200000\n",
    "EPOCHS = 10000\n",
    "LR = 0.001\n",
    "SCHEDULER_PAIENCE = 100\n",
    "MODEL_ACTIVATION_FUNC = nn.Tanh\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available else \"cpu\"\n",
    "print(\"using: \", device)\n",
    "\n",
    "log_path = \"./runs/tanh_train\"\n",
    "model_path = \"./models/tanh_train\"\n",
    "graph_path = \"./graphs\"\n",
    "\n",
    "data_root = \"./datasets/\"\n",
    "data_dict = {\"train\": None, \"val\":None}\n",
    "\n",
    "eps = 0.0000001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### INITIALISE DIRECTORIES AND LOGGERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T21:19:27.204923Z",
     "start_time": "2020-03-07T21:19:26.615482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 17] File exists: './runs/tanh_train'\n",
      "[Errno 17] File exists: './models/tanh_train'\n",
      "[Errno 17] File exists: './graphs'\n"
     ]
    }
   ],
   "source": [
    "mkdir(log_path)\n",
    "mkdir(model_path)\n",
    "mkdir(graph_path)\n",
    "    \n",
    "train_writer = tf.summary.create_file_writer(os.path.join(log_path, \"train\"))\n",
    "val_writer = tf.summary.create_file_writer(os.path.join(log_path, \"val\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LOAD DATA TO data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T21:19:28.013238Z",
     "start_time": "2020-03-07T21:19:27.921929Z"
    }
   },
   "outputs": [],
   "source": [
    "for file in os.listdir(data_root):\n",
    "    if \"train\" in file: data_dict[\"train\"] = load(file)\n",
    "    if \"test\" in file: data_dict[\"val\"] = load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### NORMALISE DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate $train\\_mean$ and $train\\_std$. Use the same mean and standard deviation to normalise both train and test data.  \n",
    "  \n",
    "<i> POSSIBLE ERROR</i>\n",
    "\n",
    "```---------------------------------------------------------------------------\n",
    "AttributeError                            Traceback (most recent call last)\n",
    "<ipython-input-17-23cdf213d68d> in <module>\n",
    "----> 1 train_mean = data_dict[\"train\"].mean()\n",
    "      2 train_std = data_dict[\"train\"].std()\n",
    "      3 \n",
    "      4 data_dict[\"train\"] = (data_dict[\"train\"] - train_mean)/ train_std\n",
    "      5 data_dict[\"test\"] = (data_dict[\"test\"] - train_mean)/train_std\n",
    "\n",
    "AttributeError: 'NoneType' object has no attribute 'mean'\n",
    "```\n",
    "<i> REASON </i>  \n",
    "Pandas tends to drop reference to data if not accessed for long time.   \n",
    "  \n",
    "<i> SOLUTION </i>  \n",
    "Just run the cells to load data again. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T21:20:07.339805Z",
     "start_time": "2020-03-07T21:20:07.324441Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m</th>\n",
       "      <th>pt</th>\n",
       "      <th>phi</th>\n",
       "      <th>eta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85972</th>\n",
       "      <td>4983.729980</td>\n",
       "      <td>23798.070312</td>\n",
       "      <td>1.962157</td>\n",
       "      <td>-0.059532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38742</th>\n",
       "      <td>5435.273438</td>\n",
       "      <td>21881.867188</td>\n",
       "      <td>1.035412</td>\n",
       "      <td>0.734343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128711</th>\n",
       "      <td>5239.408691</td>\n",
       "      <td>24608.134766</td>\n",
       "      <td>-1.121055</td>\n",
       "      <td>0.828848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28751</th>\n",
       "      <td>14121.240234</td>\n",
       "      <td>203110.953125</td>\n",
       "      <td>0.324205</td>\n",
       "      <td>-2.571108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131358</th>\n",
       "      <td>3344.826660</td>\n",
       "      <td>24897.294922</td>\n",
       "      <td>0.395331</td>\n",
       "      <td>1.440069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133326</th>\n",
       "      <td>31842.511719</td>\n",
       "      <td>236302.125000</td>\n",
       "      <td>-2.982530</td>\n",
       "      <td>0.128011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12875</th>\n",
       "      <td>5837.973145</td>\n",
       "      <td>26775.214844</td>\n",
       "      <td>-0.797112</td>\n",
       "      <td>1.042910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111439</th>\n",
       "      <td>4847.191895</td>\n",
       "      <td>25209.994141</td>\n",
       "      <td>-2.181372</td>\n",
       "      <td>-2.281394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18479</th>\n",
       "      <td>7629.757324</td>\n",
       "      <td>37038.746094</td>\n",
       "      <td>-2.670758</td>\n",
       "      <td>-0.830225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110538</th>\n",
       "      <td>9272.322266</td>\n",
       "      <td>52785.316406</td>\n",
       "      <td>-2.024980</td>\n",
       "      <td>0.590419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27945 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   m             pt       phi       eta\n",
       "85972    4983.729980   23798.070312  1.962157 -0.059532\n",
       "38742    5435.273438   21881.867188  1.035412  0.734343\n",
       "128711   5239.408691   24608.134766 -1.121055  0.828848\n",
       "28751   14121.240234  203110.953125  0.324205 -2.571108\n",
       "131358   3344.826660   24897.294922  0.395331  1.440069\n",
       "...              ...            ...       ...       ...\n",
       "133326  31842.511719  236302.125000 -2.982530  0.128011\n",
       "12875    5837.973145   26775.214844 -0.797112  1.042910\n",
       "111439   4847.191895   25209.994141 -2.181372 -2.281394\n",
       "18479    7629.757324   37038.746094 -2.670758 -0.830225\n",
       "110538   9272.322266   52785.316406 -2.024980  0.590419\n",
       "\n",
       "[27945 rows x 4 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict[\"val\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T08:27:09.053549Z",
     "start_time": "2020-03-07T08:27:09.015969Z"
    }
   },
   "outputs": [],
   "source": [
    "train_mean = data_dict[\"train\"].mean()\n",
    "train_std = data_dict[\"train\"].std()\n",
    "\n",
    "data_dict[\"train\"] = (data_dict[\"train\"] - train_mean)/ train_std\n",
    "data_dict[\"val\"] = (data_dict[\"val\"] - train_mean)/train_std\n",
    "\n",
    "train_mean = train_mean.to_numpy(dtype=np.float32)\n",
    "train_std = train_std.to_numpy(dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T08:27:09.404827Z",
     "start_time": "2020-03-07T08:27:09.385481Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m</th>\n",
       "      <th>pt</th>\n",
       "      <th>phi</th>\n",
       "      <th>eta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>132784</th>\n",
       "      <td>-0.688496</td>\n",
       "      <td>-0.607629</td>\n",
       "      <td>0.868107</td>\n",
       "      <td>0.759040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99666</th>\n",
       "      <td>-0.587358</td>\n",
       "      <td>-0.612672</td>\n",
       "      <td>-1.487534</td>\n",
       "      <td>0.117474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26629</th>\n",
       "      <td>1.051897</td>\n",
       "      <td>1.503479</td>\n",
       "      <td>-1.081401</td>\n",
       "      <td>0.773105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80473</th>\n",
       "      <td>0.788036</td>\n",
       "      <td>1.697702</td>\n",
       "      <td>-0.911068</td>\n",
       "      <td>1.813972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48229</th>\n",
       "      <td>-0.578692</td>\n",
       "      <td>-0.628716</td>\n",
       "      <td>1.619709</td>\n",
       "      <td>-0.830115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61832</th>\n",
       "      <td>-0.364437</td>\n",
       "      <td>-0.492954</td>\n",
       "      <td>-1.644013</td>\n",
       "      <td>0.033356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26867</th>\n",
       "      <td>1.190307</td>\n",
       "      <td>2.021415</td>\n",
       "      <td>1.370289</td>\n",
       "      <td>-0.926956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46232</th>\n",
       "      <td>-0.641408</td>\n",
       "      <td>-0.628934</td>\n",
       "      <td>-1.075388</td>\n",
       "      <td>-1.337238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44194</th>\n",
       "      <td>-0.593362</td>\n",
       "      <td>-0.506096</td>\n",
       "      <td>1.498136</td>\n",
       "      <td>-1.235848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59782</th>\n",
       "      <td>-0.292618</td>\n",
       "      <td>-0.545608</td>\n",
       "      <td>0.744680</td>\n",
       "      <td>-1.825007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               m        pt       phi       eta\n",
       "132784 -0.688496 -0.607629  0.868107  0.759040\n",
       "99666  -0.587358 -0.612672 -1.487534  0.117474\n",
       "26629   1.051897  1.503479 -1.081401  0.773105\n",
       "80473   0.788036  1.697702 -0.911068  1.813972\n",
       "48229  -0.578692 -0.628716  1.619709 -0.830115\n",
       "61832  -0.364437 -0.492954 -1.644013  0.033356\n",
       "26867   1.190307  2.021415  1.370289 -0.926956\n",
       "46232  -0.641408 -0.628934 -1.075388 -1.337238\n",
       "44194  -0.593362 -0.506096  1.498136 -1.235848\n",
       "59782  -0.292618 -0.545608  0.744680 -1.825007"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict[\"train\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T08:27:09.785342Z",
     "start_time": "2020-03-07T08:27:09.771628Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m</th>\n",
       "      <th>pt</th>\n",
       "      <th>phi</th>\n",
       "      <th>eta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>85972</th>\n",
       "      <td>-0.533282</td>\n",
       "      <td>-0.581905</td>\n",
       "      <td>1.087244</td>\n",
       "      <td>-0.071133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38742</th>\n",
       "      <td>-0.472437</td>\n",
       "      <td>-0.609328</td>\n",
       "      <td>0.573286</td>\n",
       "      <td>0.476957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128711</th>\n",
       "      <td>-0.498829</td>\n",
       "      <td>-0.570312</td>\n",
       "      <td>-0.622658</td>\n",
       "      <td>0.542203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28751</th>\n",
       "      <td>0.697978</td>\n",
       "      <td>1.984290</td>\n",
       "      <td>0.178861</td>\n",
       "      <td>-1.805121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131358</th>\n",
       "      <td>-0.754120</td>\n",
       "      <td>-0.566174</td>\n",
       "      <td>0.218307</td>\n",
       "      <td>0.964189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44010</th>\n",
       "      <td>-0.535048</td>\n",
       "      <td>-0.612530</td>\n",
       "      <td>-1.351654</td>\n",
       "      <td>-0.298414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20111</th>\n",
       "      <td>-0.579275</td>\n",
       "      <td>-0.544762</td>\n",
       "      <td>0.969280</td>\n",
       "      <td>-0.823615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137856</th>\n",
       "      <td>1.133802</td>\n",
       "      <td>1.711918</td>\n",
       "      <td>1.310452</td>\n",
       "      <td>-1.261355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87065</th>\n",
       "      <td>-0.521595</td>\n",
       "      <td>-0.625987</td>\n",
       "      <td>-0.821721</td>\n",
       "      <td>1.066632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39358</th>\n",
       "      <td>-0.090846</td>\n",
       "      <td>-0.279154</td>\n",
       "      <td>-0.322752</td>\n",
       "      <td>-0.276024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               m        pt       phi       eta\n",
       "85972  -0.533282 -0.581905  1.087244 -0.071133\n",
       "38742  -0.472437 -0.609328  0.573286  0.476957\n",
       "128711 -0.498829 -0.570312 -0.622658  0.542203\n",
       "28751   0.697978  1.984290  0.178861 -1.805121\n",
       "131358 -0.754120 -0.566174  0.218307  0.964189\n",
       "44010  -0.535048 -0.612530 -1.351654 -0.298414\n",
       "20111  -0.579275 -0.544762  0.969280 -0.823615\n",
       "137856  1.133802  1.711918  1.310452 -1.261355\n",
       "87065  -0.521595 -0.625987 -0.821721  1.066632\n",
       "39358  -0.090846 -0.279154 -0.322752 -0.276024"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict[\"val\"].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### INITIALISE PYTORCH DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T08:27:10.769449Z",
     "start_time": "2020-03-07T08:27:10.720833Z"
    }
   },
   "outputs": [],
   "source": [
    "train_x = torch.tensor(data_dict[\"train\"].to_numpy(), dtype=torch.float32)\n",
    "train_y = torch.tensor(data_dict[\"train\"].to_numpy(), dtype=torch.float32)\n",
    "val_x = torch.tensor(data_dict[\"val\"].to_numpy(), dtype=torch.float32)\n",
    "val_y = torch.tensor(data_dict[\"val\"].to_numpy(), dtype=torch.float32)\n",
    "\n",
    "train_dataset = TensorDataset(train_x, train_y)\n",
    "val_dataset = TensorDataset(val_x, val_y)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE)\n",
    "val_loader = DataLoader(val_dataset, shuffle=False, batch_size=len(val_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### MODEL ARCHITECTURE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"assets/Architecture%20diagram.png\" alt=\"\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T08:27:12.302592Z",
     "start_time": "2020-03-07T08:27:12.296579Z"
    }
   },
   "outputs": [],
   "source": [
    "class AE(nn.Module):\n",
    "    def __init__(self, input_dim, encoding_dim, activation):\n",
    "        super(AE, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            activation(),\n",
    "            nn.Linear(256, 128),\n",
    "            activation(),\n",
    "            nn.Linear(128, 64),\n",
    "            activation(),\n",
    "            nn.Linear(64, encoding_dim),\n",
    "            activation(),\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_dim, 64),\n",
    "            activation(),\n",
    "            nn.Linear(64, 128),\n",
    "            activation(),\n",
    "            nn.Linear(128, 256),\n",
    "            activation(),\n",
    "            nn.Linear(256, input_dim),\n",
    "        )\n",
    "        \n",
    "    def encode(self, inputs):\n",
    "        return self.encoder(inputs)\n",
    "    \n",
    "    def decode(self, embeddings):\n",
    "        return self.decoder(embeddings)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        return self.decode(self.encode(inputs))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loss function\n",
    "Loss function is the simple MSE between the decoded 4D data(from 3D encodings) and the ground truth 4D data(used to generete the 3D encoding.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T08:27:13.097843Z",
     "start_time": "2020-03-07T08:27:13.091398Z"
    }
   },
   "outputs": [],
   "source": [
    "def Loss(pred, target):\n",
    "    mseLoss = nn.MSELoss()(pred,target)\n",
    "    return mseLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### METRICS\n",
    "These metrics are tracked for the validation set, for each step of the training.  \n",
    "The system for adding new metrics is modular. New metrics can be added/tracked by simply defining a function in the following form,\n",
    "<pre><code>\n",
    "<b>def metric_name</b>(pred: <i>torch tensor</i>, target: <i>torch tensor</i>):\n",
    "    <b>return</b> metric_value: <i>1d torch tensor</i>\n",
    "</code></pre>\n",
    "and then adding the function name to the metrics array.  \n",
    "  \n",
    "All the tracked metrics appear in tensorboard with the name of the function as label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T08:27:14.835944Z",
     "start_time": "2020-03-07T08:27:14.832194Z"
    }
   },
   "outputs": [],
   "source": [
    "def MSE_metric(pred, target):\n",
    "    return nn.MSELoss()(pred, target).cpu().detach().numpy()\n",
    "\n",
    "def MAPE_metric(pred, target):\n",
    "    std = torch.from_numpy(train_std).to(device)\n",
    "    mean = torch.from_numpy(train_mean).to(device)\n",
    "    return  torch.abs(std*(pred - target)/(target*std+mean+eps)).mean().cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN LOOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### INSTANTIATE MODEL, LOSS, METRICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T08:01:41.369641Z",
     "start_time": "2020-03-07T08:01:38.839429Z"
    }
   },
   "outputs": [],
   "source": [
    "model = AE(4,3, MODEL_ACTIVATION_FUNC).to(device)\n",
    "loss_func = Loss\n",
    "metrics = [MAPE_metric]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### INSTANTIATE THE OPTIMISER AND SCHEDULER\n",
    "Optimiser : Adam  \n",
    "Scheduler : ReduceLROnPlateau \n",
    ">Reduce Learning Rate when validation loss does not decrease for SCHEDULER_PATIENCS epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T08:01:41.377425Z",
     "start_time": "2020-03-07T08:01:41.371188Z"
    }
   },
   "outputs": [],
   "source": [
    "optimiser = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimiser, patience=SCHEDULER_PAIENCE, verbose=True, cooldown=10,factor=0.1, min_lr=1e-7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TRAIN LOOP\n",
    "1. The loop runs for EPOCH epochs.   \n",
    "2. For each batch, after gradient decent, loss and metrics are caluclated.\n",
    "3. In each epoch, the metrics and losses are calculated for both train set and val set. Actually average of metrics calculated per batch, is taken in both cases.\n",
    "4. The model with the least validation loss so far is saved in model_path/best.pth and model with the latest model is stored in {model_path}/latest.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-06T20:13:02.385612Z",
     "start_time": "2020-03-06T20:13:02.380487Z"
    }
   },
   "outputs": [],
   "source": [
    "best_loss = 100000000 #the best validation loss seen so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-06T03:17:10.655590Z",
     "start_time": "2020-03-05T22:23:33.332905Z"
    }
   },
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(0, EPOCHS)):\n",
    "    \n",
    "    # aggregators for batch metrics on train set\n",
    "    batch_train_losses = []\n",
    "    batch_train_metrics = {metric.__name__:[] for metric in metrics}\n",
    "    \n",
    "    for i, (inputs, targets) in enumerate(train_loader): # for each batch\n",
    "        \n",
    "        # set the initial gradients to 0\n",
    "        optimiser.zero_grad()\n",
    "        inputs = inputs.to(device)\n",
    "        target = targets.to(device)\n",
    "        \n",
    "        pred = model(inputs)\n",
    "        loss = loss_func(pred, target)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimiser.step()\n",
    "        \n",
    "        # calculate all the metrics in no_grad mode to make the calculation slightly faster\n",
    "        with torch.no_grad():\n",
    "            batch_train_losses.append(loss.detach().cpu().numpy())\n",
    "            for metric in metrics:\n",
    "                name = metric.__name__\n",
    "                batch_train_metrics[name].append(metric(pred, target))\n",
    "    \n",
    "    # the final epoch loss and metrics for the train set\n",
    "    # they are caluclated by taking mean of metrics calculated for all the batches\n",
    "    train_loss = np.mean(batch_train_losses)\n",
    "    train_metrics = {}\n",
    "    for metric in metrics:\n",
    "        name = metric.__name__\n",
    "        train_metrics[name] = np.mean(batch_train_metrics[name])\n",
    "    \n",
    "    # calculate the val loss and val metrics in no_grad mode.\n",
    "    # NOTE: since validation of the entire validation is done in 1 go,\n",
    "    # we don't have any per batch aggregators (ie, no batch_val_losses)\n",
    "    with torch.no_grad(): \n",
    "        for val_x, val_y in val_loader:\n",
    "            val_x = val_x.to(device)\n",
    "            val_y = val_y.to(device)\n",
    "            \n",
    "            pred = model(val_x)\n",
    "            val_loss = loss_func(pred, val_y).cpu().detach().numpy()\n",
    "            val_metrics = {metric.__name__:metric(pred, val_y) for metric in metrics}\n",
    "\n",
    "    # scheduler decides on whether to change the learning rate depending\n",
    "    # depending in the val_losses seen for.\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # log the train loss to tensorboard\n",
    "    log(train_writer, {\"loss\":train_loss}, epoch)\n",
    "    # log the train metrics to tensorboard\n",
    "    log(train_writer, train_metrics, epoch)\n",
    "    \n",
    "    # log the val loss to tensorboard    \n",
    "    log(val_writer, {\"loss\":val_loss}, epoch)\n",
    "    # log the val metrics to tensorboard\n",
    "    log(val_writer, val_metrics, epoch)\n",
    "    \n",
    "    # if val loss becomes less than the best seen so far, save the model in model_path/best.pth\n",
    "    if val_loss < best_loss:\n",
    "        print(f\"{epoch}: val_loss improved: {best_loss}->{val_loss}\")\n",
    "        best_loss = val_loss\n",
    "        torch.save(model.state_dict(), f\"{model_path}/best.pth\")\n",
    "    \n",
    "    # save the model in model_path/latest.pth, regardless of whether imporovement happens or not.\n",
    "    if epoch%10==0: torch.save(model.state_dict(), f\"{model_path}/latest.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TENSORBOARD LOGGING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T23:07:53.432860Z",
     "start_time": "2020-03-07T23:07:50.399448Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-3ce127de6059356a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-3ce127de6059356a\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 12345;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir={log_path} --port=12345"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LOAD BEST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T08:27:21.432803Z",
     "start_time": "2020-03-07T08:27:18.919912Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AE(4,3,MODEL_ACTIVATION_FUNC)\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(f\"{model_path}/best.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GENERATE THE DECODED 4D OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T08:27:22.300917Z",
     "start_time": "2020-03-07T08:27:22.271753Z"
    }
   },
   "outputs": [],
   "source": [
    "# load val data as a torch tensor (batch size x 4)\n",
    "val_data = torch.from_numpy(data_dict[\"val\"].to_numpy(dtype=np.float32))\n",
    "\n",
    "# pred is the predicted 4D output using the val data,\n",
    "# and convert it to numpy.ndarray\n",
    "pred = model(val_data.to(device)).cpu().detach().numpy()\n",
    "\n",
    "#convert val data to a numpy.ndarray\n",
    "val_data = val_data.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### UN-NORMALISE THE 4D PREDICTED OUTPUT AND 4D VALIDATION INPUT "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is fed val data that has been normalised (using <i> train_mean and train_std </i>).   \n",
    "To get qualitative results we need to get both the predictions and val data back to the original domain.  \n",
    "To get $x$ back to the original domain \n",
    "$$\n",
    "x\\_original = x*train\\_std + train\\_mean\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T08:27:23.835042Z",
     "start_time": "2020-03-07T08:27:23.831991Z"
    }
   },
   "outputs": [],
   "source": [
    "pred = unNormalise(pred, train_mean, train_std)\n",
    "val_data = unNormalise(val_data, train_mean, train_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GRAPHING FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T08:27:24.582130Z",
     "start_time": "2020-03-07T08:27:24.574718Z"
    }
   },
   "outputs": [],
   "source": [
    "def makeReconstructionBar(pred, target, name, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Creates graph for the predicted 4d output and 4d val input, such that the output is \n",
    "    layerd on top of the input, with some transparency. This way we can visually see how \n",
    "    much of a deviation there for each point.\n",
    "        Savepath: graph_path/name.png\n",
    "    \n",
    "    target: red (background)\n",
    "    pred: blue (foreground) \n",
    "\n",
    "    @params: pred -> predicted unnormalised values for 1 feature\n",
    "    @params: target -> the ground truth unnormalised values for 1 feature\n",
    "    @params: name -> name of the save file\n",
    "    @params: alpha -> amount of transparency o\n",
    "    \"\"\"\n",
    "    back = target\n",
    "    front = pred\n",
    "    plt.bar(np.arange(back.shape[0]), back, color=\"r\", label=\"Ground Truth Value\")\n",
    "    plt.bar(np.arange(front.shape[0]), front, color=\"b\", alpha=alpha, label=\"Reconstructed Value\")\n",
    "    \n",
    "    plt.title(f\"{name.split('.')[0]}\")\n",
    "    plt.xlabel(\"Sample points\")\n",
    "    plt.ylabel(\"Value\")\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.savefig(f\"{graph_path}/{name}\")\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T08:27:25.018431Z",
     "start_time": "2020-03-07T08:27:25.005798Z"
    }
   },
   "outputs": [],
   "source": [
    "def makeMAPEScatter(pred, target, name, thresh=1):\n",
    "    \"\"\"\n",
    "    Creates a scatter graph for the mape per point for 1 feature of the val set.\n",
    "    The values greater than thresh are set equal to thresh.\n",
    "        Savepath: graph_path/name.png\n",
    "        \n",
    "    @params: pred -> predicted unnormalised values for 1 feature\n",
    "    @params: target -> the ground truth unnormalised values for 1 feature\n",
    "    @params: name -> name of the save file\n",
    "    @params: thresh -> the cutoff threshold.\n",
    "    \"\"\"\n",
    "    mape = np.abs((target-pred)/(target+0.000001))\n",
    "    mask = (mape>=thresh)\n",
    "    mape = mape*(1-mask) + np.ones(mape.shape)*(mask)\n",
    "    plt.scatter(np.arange(mape.shape[0]), mape, color=\"r\")\n",
    "    \n",
    "    plt.title(f\"{name.split('.')[0]}\")\n",
    "    plt.xlabel(\"Sample points\")\n",
    "    plt.ylabel(\"MAPE Value\")\n",
    "    plt.savefig(f\"{graph_path}/{name}\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T08:27:25.584376Z",
     "start_time": "2020-03-07T08:27:25.569741Z"
    }
   },
   "outputs": [],
   "source": [
    "def makeMAPEDistributionHist(pred, target, name, thresh=1):\n",
    "    \"\"\"\n",
    "    Creates 2 graphs.\n",
    "        \n",
    "        1 histogram showing the number of points for which the MAPE lies in bins\n",
    "        of 0.1, starting from 0 and till 1.\n",
    "            Savepath: graph_path/name.png\n",
    "            \n",
    "        1 historgram showing the number of points for which the MAPE lies in bins\n",
    "        of 0.1, starting from 0 and till 1. The y-scale is log(base 10).\n",
    "            Savepath: graph_path/log_name.png\n",
    "            \n",
    "    @params: pred -> predicted unnormalised values for 1 feature\n",
    "    @params: target -> the ground truth unnormalised values for 1 feature\n",
    "    @params: name -> name of the save file\n",
    "    @params: thresh -> the cutoff threshold.\n",
    "    \"\"\"\n",
    "    mape = np.abs((target-pred)/(target+0.000001))\n",
    "    mask = (mape>=thresh)\n",
    "    mape = mape*(1-mask) + np.ones(mape.shape)*(mask)\n",
    "    \n",
    "    plt.hist(mape, log=False)\n",
    "    plt.title(f\"{name.split('.')[0]}\")\n",
    "    plt.xlabel(\"Bins\")\n",
    "    plt.ylabel(\"Number of points\")\n",
    "    plt.savefig(f\"{graph_path}/{name}\")\n",
    "    plt.close()\n",
    "    \n",
    "    plt.hist(mape, log=True)\n",
    "    plt.title(f\"log_{name.split('.')[0]}\")\n",
    "    plt.xlabel(\"Bins\")\n",
    "    plt.ylabel(\"Number of points (log10 scale)\")\n",
    "    plt.savefig(f\"{graph_path}/log_{name}\")\n",
    "    plt.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### LOOP OVER THE FEATURES TO MAKE THE GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T08:27:26.709162Z",
     "start_time": "2020-03-07T08:27:26.704089Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['m', 'pt', 'phi', 'eta']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = list(data_dict[\"train\"].columns)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-07T08:31:40.877173Z",
     "start_time": "2020-03-07T08:27:27.334166Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/envs/cern/lib/python3.7/site-packages/ipykernel_launcher.py:1: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d26c92956a34883a9640b57ad7cef9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(val_data.shape[1])):\n",
    "    makeMAPEScatter(pred[:,i], val_data[:,i], name=f\"mape_scatter_{features[i]}.png\")\n",
    "    makeReconstructionBar(pred[:, i],val_data[:, i], name=f\"reconstructed_bar_{features[i]}.png\")\n",
    "    makeMAPEDistributionHist(pred[:,i], val_data[:,i], name=f\"mape_ditribution_hist_{features[i]}.png\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cern",
   "language": "python",
   "name": "cern"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
